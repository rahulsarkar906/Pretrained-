{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams: Is a set of continuous sequence of n items from a given sequence of large text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rahul.b.sarkar/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a function to extract n-grams from text\n",
    "def get_ngrams(txt, n):\n",
    "    n_grams = ngrams(nltk.word_tokenize(txt),n)\n",
    "    return [' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = 'This is a course of Natural Language Processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram: ['This', 'is', 'a', 'course', 'of', 'Natural', 'Language', 'Processing']\n",
      "2-gram: ['This is', 'is a', 'a course', 'course of', 'of Natural', 'Natural Language', 'Language Processing']\n",
      "3-gram: ['This is a', 'is a course', 'a course of', 'course of Natural', 'of Natural Language', 'Natural Language Processing']\n",
      "4-gram: ['This is a course', 'is a course of', 'a course of Natural', 'course of Natural Language', 'of Natural Language Processing']\n"
     ]
    }
   ],
   "source": [
    "print(\"1-gram:\", get_ngrams(txt, 1))\n",
    "print(\"2-gram:\", get_ngrams(txt, 2))\n",
    "print(\"3-gram:\", get_ngrams(txt, 3))\n",
    "print(\"4-gram:\", get_ngrams(txt, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: 1-gram is called unigram, 2-gram, and 3-gram as bigram and trigram respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    punt_removed = [w for w in words if w.lower() not in string.punctuation]\n",
    "    return \" \".join(punt_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Python skills, and Numpy skills are equally important for data analysis. Python skills, and linear algebra are important for machine learning algorithms\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = remove_punctuations(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting bigrams\n",
    "bigrams = get_ngrams(text, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting bigrams\n",
    "bigrams_count = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(bigrams_count, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming index and column name\n",
    "df = df.rename(columns={'index':'words', 0:'frequency'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     frequency\n",
      "Python skills                2\n",
      "skills and                   2\n",
      "and Numpy                    1\n",
      "Numpy skills                 1\n",
      "skills are                   1\n",
      "are equally                  1\n",
      "equally important            1\n",
      "important for                2\n",
      "for data                     1\n",
      "data analysis                1\n",
      "analysis Python              1\n",
      "and linear                   1\n",
      "linear algebra               1\n",
      "algebra are                  1\n",
      "are important                1\n",
      "for machine                  1\n",
      "machine learning             1\n",
      "learning algorithms          1\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "\n",
    "http://www.nltk.org/api/nltk.html#nltk.util.ngrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
